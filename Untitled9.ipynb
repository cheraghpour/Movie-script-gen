{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZnz6Xgt4ZkE"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4oX4Rs54bX3"
      },
      "source": [
        "path_to_file = \"scripts.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2lM65Y94d2_",
        "outputId": "1cb523a9-45d1-414a-bb87-223d3113b4b6"
      },
      "source": [
        "# Read, then decode for py2 compat.\r\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\r\n",
        "# length of text is the number of characters in it\r\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 13631487 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAzJl-Vi_L4i",
        "outputId": "785c9a4c-acd2-4855-d7af-9a89e00adeba"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    TWELVE MONKEYS\r\n",
            "     \r\n",
            "            An original screenplay by\r\n",
            "\r\n",
            "    David Peoples\r\n",
            "           &\r\n",
            "    Janet Peoples\r\n",
            "\r\n",
            "     Inspired by\r\n",
            "     \r\n",
            "   LA JETEE, a Chris Marker Film\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " Production Draft\r\n",
            " June 27, 1994\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " FADE IN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-90FvAz_RI_",
        "outputId": "307d7e24-8658-42d9-a02d-60b94afd91cc"
      },
      "source": [
        "# The unique characters in the file\r\n",
        "vocab = sorted(set(text))\r\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t5LTdEi_f9o",
        "outputId": "33f0d80f-e0f8-41f4-c95f-af85dc6cc388"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\r\n",
        "\r\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\r\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddaDoabX_ieq"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\r\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M60p1h2m_mBl",
        "outputId": "9b93bda7-b9e8-42c1-b453-07d1ff8ff324"
      },
      "source": [
        "ids = ids_from_chars(chars)\r\n",
        "ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[66, 67, 68, 69, 70, 71, 72], [89, 90, 91]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUO2rRC8_n3V"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\r\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8W1t0sC_q-2",
        "outputId": "419cc4b7-ab6c-48b7-e57e-6a760fe97005"
      },
      "source": [
        "chars = chars_from_ids(ids)\r\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDYuXN9B_sur",
        "outputId": "5bfb845d-8fcd-445c-ee0d-8bce539e8b0b"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXrrt4Gz_vQE"
      },
      "source": [
        "def text_from_ids(ids):\r\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I2axtg9_xLH",
        "outputId": "5c5667e3-d661-418b-ef91-7df15c678327"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\r\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13631487,), dtype=int64, numpy=array([ 4,  4,  4, ...,  4, 69, 74])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuBN1uvX_zAH"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFtOD9OZ_1Bs",
        "outputId": "9294e225-6ca0-47c1-da61-98d06d9b3fbe"
      },
      "source": [
        "for ids in ids_dataset.take(10):\r\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            "T\n",
            "W\n",
            "E\n",
            "L\n",
            "V\n",
            "E\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwWzaFva_2vY"
      },
      "source": [
        "seq_length = 100\r\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBBcZTPx_59M",
        "outputId": "1ca13b2a-3eee-4689-a1e1-829bdd9e680e"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\r\n",
        "\r\n",
        "for seq in sequences.take(1):\r\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b' ' b' ' b' ' b' ' b'T' b'W' b'E' b'L' b'V' b'E' b' ' b'M' b'O' b'N'\n",
            " b'K' b'E' b'Y' b'S' b'\\r' b'\\n' b' ' b' ' b' ' b' ' b' ' b'\\r' b'\\n' b' '\n",
            " b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b'A' b'n' b' '\n",
            " b'o' b'r' b'i' b'g' b'i' b'n' b'a' b'l' b' ' b's' b'c' b'r' b'e' b'e'\n",
            " b'n' b'p' b'l' b'a' b'y' b' ' b'b' b'y' b'\\r' b'\\n' b'\\r' b'\\n' b' ' b' '\n",
            " b' ' b' ' b'D' b'a' b'v' b'i' b'd' b' ' b'P' b'e' b'o' b'p' b'l' b'e'\n",
            " b's' b'\\r' b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
            " b'&' b'\\r' b'\\n'], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSrLWlyB_791",
        "outputId": "88a58d98-c00f-449a-d372-381f758c88e8"
      },
      "source": [
        "for seq in sequences.take(5):\r\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'    TWELVE MONKEYS\\r\\n     \\r\\n            An original screenplay by\\r\\n\\r\\n    David Peoples\\r\\n           &\\r\\n'\n",
            "b'    Janet Peoples\\r\\n\\r\\n     Inspired by\\r\\n     \\r\\n   LA JETEE, a Chris Marker Film\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n Production'\n",
            "b' Draft\\r\\n June 27, 1994\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n FADE IN:\\r\\n\\r\\n INT.  CONCOURSE/AIRPORT TERMINAL - BAY\\r\\n\\r\\n CLOS'\n",
            "b'E ON A FACE.  A nine year old boy, YOUNG COLE, his eyes wide\\r\\n with wonder. watching something intent'\n",
            "b'ly.  We HEAR the sounds of\\r\\n the P.A. SYSTEM droning Flight Information mingled with the\\r\\n sounds of '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Zk7qPB_-Zt"
      },
      "source": [
        "def split_input_target(sequence):\r\n",
        "    input_text = sequence[:-1]\r\n",
        "    target_text = sequence[1:]\r\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzbrSc_CAAiZ",
        "outputId": "ceea3d51-f562-4d65-f90c-6702560fe614"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5_BySQIADYQ"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJKU5Fh9AF5e",
        "outputId": "e6c49b36-8210-433d-abde-20b2139b8717"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\r\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\r\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'    TWELVE MONKEYS\\r\\n     \\r\\n            An original screenplay by\\r\\n\\r\\n    David Peoples\\r\\n           &\\r'\n",
            "Target: b'   TWELVE MONKEYS\\r\\n     \\r\\n            An original screenplay by\\r\\n\\r\\n    David Peoples\\r\\n           &\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-XdnChAHsw",
        "outputId": "d89d13ad-5a9c-4338-f8d6-14370a509276"
      },
      "source": [
        "# Batch size\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "BUFFER_SIZE = 1000\r\n",
        "\r\n",
        "dataset = (\r\n",
        "    dataset\r\n",
        "    .shuffle(BUFFER_SIZE)\r\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\r\n",
        "\r\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdWXYDu_ANFj"
      },
      "source": [
        "# Length of the vocabulary in chars\r\n",
        "vocab_size = len(vocab)\r\n",
        "\r\n",
        "# The embedding dimension\r\n",
        "embedding_dim = 256\r\n",
        "\r\n",
        "# Number of RNN units\r\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eAPj2oIAPvA"
      },
      "source": [
        "class MyModel(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\r\n",
        "    super().__init__(self)\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\r\n",
        "                                   return_sequences=True, \r\n",
        "                                   return_state=True)\r\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\r\n",
        "    x = inputs\r\n",
        "    x = self.embedding(x, training=training)\r\n",
        "    if states is None:\r\n",
        "      states = self.gru.get_initial_state(x)\r\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\r\n",
        "    x = self.dense(x, training=training)\r\n",
        "\r\n",
        "    if return_state:\r\n",
        "      return x, states\r\n",
        "    else: \r\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbZRkzjYASoV"
      },
      "source": [
        "model = MyModel(\r\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\r\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\r\n",
        "    embedding_dim=embedding_dim,\r\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdBfQk9bAUa1",
        "outputId": "046a755f-717d-4558-ccda-852773062f20"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
        "    example_batch_predictions = model(input_example_batch)\r\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TiLf1ByAXaj",
        "outputId": "1f79064d-0068-4a6a-a91a-080121f84fc9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  24832     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  99425     \n",
            "=================================================================\n",
            "Total params: 4,062,561\n",
            "Trainable params: 4,062,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKDqlF-eAdxA"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\r\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Ty0asgAgzf",
        "outputId": "7bed1e20-1043-4893-e6a5-215d7bae2030"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5, 54, 66, 44, 57, 94, 21, 68, 28, 57, 96, 65, 10, 18,  4,  2, 48,\n",
              "       40, 36, 16,  9, 12,  4,  3, 90, 39, 24,  9, 82, 57, 48, 29, 80, 32,\n",
              "        6, 28, 24, 73, 21, 27, 36, 70, 80, 22, 36,  6, 71, 62, 69, 75, 43,\n",
              "       89, 15, 94, 70,  2,  5, 96, 49, 40, 82,  6, 73, 62, 88,  3, 82, 67,\n",
              "       31,  0, 14, 82, 92, 92, 59, 19, 83, 19, 79, 75, 67, 62, 20, 66, 60,\n",
              "       49, 76, 91, 82,  5, 36, 15, 56, 86,  9, 75, 22, 26, 12, 66])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBdu7eiEAi3l",
        "outputId": "2b5932be-bcf9-4fd5-b406-5ee119958482"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\r\n",
        "print()\r\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'ORD/FREEWAY\\r\\n\\r\\n A ROLODEX CARD with an address on \"Outerbridge Road\" for \"Jeffrey\\r\\n Mason c/o Dr. Ma'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'!SaIV}1c8V\\xc2\\xb0`&. \\nMEA,%( \\ryD4%qVM9o<\"84h17Aeo2A\"f[djHx+}e\\n!\\xc2\\xb0NEq\"h[w\\rqb;*q{{X/r/njb[0aYNkzq!A+Uu%j26(a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW9i5TSvAk2j"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKVnPSz1AqMw",
        "outputId": "f4b292a0-9cce-49a8-c258-a156223caf32"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\r\n",
        "mean_loss = example_batch_loss.numpy().mean()\r\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\r\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.574714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm5d2eosAsGt",
        "outputId": "30d7a3bc-7a6b-4982-c8f3-a3e8f016f4a0"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.000305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WIuYdAEAu6j"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIaYTbl8Aw7X"
      },
      "source": [
        "# Directory where the checkpoints will be saved\r\n",
        "checkpoint_dir = './deneme2'\r\n",
        "# Name of the checkpoint files\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n",
        "\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_prefix,\r\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h5RaKaXAytt"
      },
      "source": [
        "EPOCHS = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "IK2NRMDlBCWO",
        "outputId": "4967aef0-5ccb-40c8-80ca-7ce3825c1824"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2108/2108 [==============================] - 113s 53ms/step - loss: 1.7256\n",
            "Epoch 2/50\n",
            "2108/2108 [==============================] - 118s 56ms/step - loss: 1.0203\n",
            "Epoch 3/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.9422\n",
            "Epoch 4/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.9048\n",
            "Epoch 5/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8828\n",
            "Epoch 6/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8679\n",
            "Epoch 7/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8581\n",
            "Epoch 8/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8518\n",
            "Epoch 9/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8473\n",
            "Epoch 10/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8454\n",
            "Epoch 11/50\n",
            "2108/2108 [==============================] - 119s 57ms/step - loss: 0.8439\n",
            "Epoch 12/50\n",
            "2108/2108 [==============================] - 119s 57ms/step - loss: 0.8430\n",
            "Epoch 13/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8452\n",
            "Epoch 14/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8452\n",
            "Epoch 15/50\n",
            "2108/2108 [==============================] - 120s 57ms/step - loss: 0.8434\n",
            "Epoch 16/50\n",
            " 561/2108 [======>.......................] - ETA: 1:27 - loss: 0.8497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-25e345c13e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lloGkWymBGhl"
      },
      "source": [
        "class OneStep(tf.keras.Model):\r\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\r\n",
        "    super().__init__()\r\n",
        "    self.temperature=temperature\r\n",
        "    self.model = model\r\n",
        "    self.chars_from_ids = chars_from_ids\r\n",
        "    self.ids_from_chars = ids_from_chars\r\n",
        "\r\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\r\n",
        "    skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\r\n",
        "    sparse_mask = tf.SparseTensor(\r\n",
        "        # Put a -inf at each bad index.\r\n",
        "        values=[-float('inf')]*len(skip_ids),\r\n",
        "        indices = skip_ids,\r\n",
        "        # Match the shape to the vocabulary\r\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())]) \r\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def generate_one_step(self, inputs, states=None):\r\n",
        "    # Convert strings to token IDs.\r\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\r\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\r\n",
        "\r\n",
        "    # Run the model.\r\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits] \r\n",
        "    predicted_logits, states =  self.model(inputs=input_ids, states=states, \r\n",
        "                                          return_state=True)\r\n",
        "    # Only use the last prediction.\r\n",
        "    predicted_logits = predicted_logits[:, -1, :]\r\n",
        "    predicted_logits = predicted_logits/self.temperature\r\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\r\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\r\n",
        "\r\n",
        "    # Sample the output logits to generate token IDs.\r\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\r\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\r\n",
        "    \r\n",
        "    # Convert from token ids to characters\r\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\r\n",
        "\r\n",
        "    # Return the characters and model state.\r\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVYxatIOD7DO"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gvhEDNdD9LF",
        "outputId": "083bc4dc-1dfd-47ef-f87c-7b1dfbaee07e"
      },
      "source": [
        "start = time.time()\r\n",
        "states = None\r\n",
        "next_char = tf.constant(['Ceza:'])\r\n",
        "result = [next_char]\r\n",
        "\r\n",
        "for n in range(10000):\r\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\r\n",
        "  result.append(next_char)\r\n",
        "\r\n",
        "result = tf.strings.join(result)\r\n",
        "end = time.time()\r\n",
        "\r\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\r\n",
        "\r\n",
        "print(f\"\\nRun time: {end - start}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ceza:\r\n",
            "                                                                        70.\r\n",
            "\r\n",
            "\r\n",
            "A chain are ractor closes in close. Thirmback is porneging, but steaming\r\n",
            "water as someone sleeps aside; it developing inside the camera.\r\n",
            "\r\n",
            "Catherine's screen listens to a halt-eyed Pable.\r\n",
            "\r\n",
            "    JULIA (CONT'D)\r\n",
            "   (dryating at the door)\r\n",
            "  How do you didn't know? I don't go for\r\n",
            "  him!\r\n",
            "\r\n",
            "The churney's open light on an animal has landing,\r\n",
            "revealing the (with rat) And the strobes scatter\r\n",
            "          about...\r\n",
            "\r\n",
            "Matt and An ABSENT-LOVE POLICE on the bar, feeling the\r\n",
            "Gate For water...\r\n",
            "\r\n",
            "Their last fade is hearing the word with concroting fingers.\r\n",
            "\r\n",
            "                    \r\n",
            "\r\n",
            "                                                                    CUT.\r\n",
            "\r\n",
            "                                   MOTHER\r\n",
            "                    Sorry to act out the guy I'm\r\n",
            "                    not leaving, Matt.\r\n",
            "          His cry--Ared down there this as.. I don't know.\r\n",
            "\r\n",
            "                     NEYTIRI\r\n",
            "                  I asked you hear real fraiguit\r\n",
            "                    intent... I'm starting out new\r\n",
            "                    prince of strong...\r\n",
            "\r\n",
            "                      STEVE\r\n",
            "          Andrew's fucking charlier?\r\n",
            "\r\n",
            "                                   WAYNO\r\n",
            "                    That's the vais.\r\n",
            "                    ANDREW (O.S.) (CONT'D)\r\n",
            "           You don't need to know, you've mother for\r\n",
            "                    ourse than nuts; forty-\r\n",
            "\r\n",
            "Mounce ffarms the brushly.\r\n",
            "\r\n",
            "It's hand motionless, and try to pull the chain of M.  30.\r\n",
            " Thirty contests again the dog.\r\n",
            "\r\n",
            "                                   HOLD\r\n",
            "                    Multial treathank which poors nick opened\r\n",
            "                    it pants.  And we can not come in falls\r\n",
            "                    on the door... you don't need charge\r\n",
            "                    a 15 feet, but in my reason.\r\n",
            "\r\n",
            "                           PAUL\r\n",
            "          Yeah, are you, door mental life on\r\n",
            "          and then, if you throw dangerous.\r\n",
            "\r\n",
            "A police generica is brushed.\r\n",
            "\r\n",
            "                                                            CUT.\r\n",
            "\r\n",
            "They pass through the dancing's, as we see...\r\n",
            "\r\n",
            "Andrew shoots up full on the fall to one banding with a Woman.\r\n",
            "\r\n",
            "We watching, playing molding swiss in, transcoins.\r\n",
            "\r\n",
            "They're coming up from the young totacing.\r\n",
            "\r\n",
            "The Channel enters from the bar sound, and then then, below,\r\n",
            " fucking love worse\r\n",
            "\r\n",
            "ALTERED a feeling Floating and combets out at the beact, too\r\n",
            "intently clear is a transton, allowed toward the camera.\r\n",
            "\r\n",
            "Andrew's bashes the ceiling. Andrew turns and coughs.\r\n",
            "\r\n",
            "We HOW, retrieves her tracer.\r\n",
            "\r\n",
            "Neither shoots she notices Andrew-types with pink.  Captain\r\n",
            "laughs.\r\n",
            "\r\n",
            "                                   DOOLITTLE\r\n",
            "                    Supernaigle, you don't just fant your chance.\r\n",
            "\r\n",
            "               ANDREW (O.S.)\r\n",
            "          Nothing. now.\r\n",
            "\r\n",
            "                    STEVE\r\n",
            "          I don't alley rank addresses. This\r\n",
            "          pedesta hears a reason to have\r\n",
            "           shit. Metaur, it won't just little\r\n",
            "          Mymaneup... what we do need... here\r\n",
            "                    you want to do school?\r\n",
            "\r\n",
            "                    MATT\r\n",
            "          I don't got this.\r\n",
            "\r\n",
            "                    CASEY\r\n",
            "          Push out and mechanism.  That was\r\n",
            "          gasp little time for your dating\r\n",
            "          the family, and it makes us\r\n",
            "          fucking somewhere in silence. Glasse\r\n",
            "          ceases like this. And we are\r\n",
            "          not without up, do, Andrew, right.\r\n",
            "\r\n",
            "                    ANDREW\r\n",
            "          I says.. And I was going to be of flush\r\n",
            "          than that. He's against a assemite.\r\n",
            "          All being come on in a mechanism pressing for\r\n",
            "          and they are promptly filming something now... and if\r\n",
            "          why we can't get the sins. Mate right\r\n",
            "          about this, we get a strong product,\r\n",
            "          Callin...\r\n",
            "\r\n",
            " INT. HOIST - DAY\r\n",
            "\r\n",
            " Calmful he is now flowing against the boy's arms...\r\n",
            "\r\n",
            "\"Mother\" ophirs looking down across Andrew. The POLICE OFFICERS drift down from\r\n",
            "an eerie lawn of RETURN NOISIST STEVE OVER TO VAS- ANDREW'S\r\n",
            "STILGER SHOWER... PEOPLE begins to trick them at Cathetic, nudge\r\n",
            "plains down.  Do you save it?\r\n",
            "\r\n",
            "STEVE'S OFFICE\r\n",
            "\r\n",
            "Dizzines.  She feels the science of the target-back doors, in pain, tending,\r\n",
            "dots with a cat-way through Senth And Ramsey. 9allant-\r\n",
            "\r\n",
            "                                                   CUT.\r\n",
            "\r\n",
            "Andrew is creeping as he pockets lots of diserscool.\r\n",
            "\r\n",
            "                        DOE SMITH\r\n",
            "           Mr. Detmer.\r\n",
            "\r\n",
            "Andrew speaks in hhair, wised to fire, maybe. There's a rather\r\n",
            "dry age in near BLACK AND FBOT.\r\n",
            "\r\n",
            "Three years old.  Can he beaven's happy trap that happens, and harler\r\n",
            "together...\r\n",
            "\r\n",
            "Andrew's raped over A Harpoor, standing with bears and srips \r\n",
            "with an emergency room, pows while indigo to be seeies of her chest\r\n",
            "blast for a potatoly, with cover and the camera.\r\n",
            "\r\n",
            "                                                CUT.\r\n",
            "\r\n",
            "They throw across the flecied down-\r\n",
            "                                                  CUT.\r\n",
            "                         TWALPER\r\n",
            "                    For why we're going to brat top off and\r\n",
            "                         \r\n",
            "\r\n",
            "                                                           60.\r\n",
            "\r\n",
            "\r\n",
            "Now as He never hear it.\r\n",
            "\r\n",
            "Carrieare.  Even lots of call open, his name breath of hide doggies\r\n",
            "displays his tail.\r\n",
            "\r\n",
            "                                         CUT.\r\n",
            "\r\n",
            "Andrew is septraking, making a dream.\r\n",
            "\r\n",
            "                       BEVILACQUA\r\n",
            "          Yeah, yeah, this is AUPBERLAMA,\r\n",
            "          my friends. You may Says. \r\n",
            "                    Finance the pound of food.\r\n",
            "\r\n",
            "                         MOTHER (CONT'D)\r\n",
            "          Mr. Daddy.\r\n",
            "\r\n",
            "Matt tries to push his church to be seen on his hands. As a monitor\r\n",
            " pleases ago, let the screaming stops, strobing the towel,\r\n",
            " as we see she closes and sees the camera in the background.\r\n",
            "\r\n",
            "    HENRY (CONT'D)\r\n",
            "  Co-Hoiston is a cell-past.  This one.\r\n",
            "\r\n",
            " They jump stuck in his face, connected to the other `ti-still\r\n",
            "has.  There is a sweat in the side, screaming.  We've\r\n",
            "\r\n",
            "                                                         22.\r\n",
            "\r\n",
            "\r\n",
            "                     NOVAK\r\n",
            "          Do we have, now hi to.  I am, that\r\n",
            "          it's just a black nightmare, and I gave you a\r\n",
            "          moment to kill this. does her, as we\r\n",
            "          care for us.\r\n",
            "           (bearing fuck)\r\n",
            " I'm neitrenting... a doll, renewing.\r\n",
            "\r\n",
            " Greg's basket and fuel guess fast as down to his FACEMENT Dollan\r\n",
            " and rather talk, and pulled up and shoot up. then the camera\r\n",
            "sees the deal striking on the action, Catherine waits as Andrew\r\n",
            "turns back to Watching Constitution.\r\n",
            "\r\n",
            "                     FLEEN DRIVE\r\n",
            "                                (malfing)\r\n",
            "                    What kind of joke? Are you us?\r\n",
            "                                                                   C.T.\r\n",
            "                    Monitor, Armanishle, and your typural shruns\r\n",
            "          when No recognition is at langunful\r\n",
            "          Starghive of Traia.\r\n",
            "              (beat)\r\n",
            "          Matthian mind is not the girl\r\n",
            "          shot.\r\n",
            "                                                                     CUT.\r\n",
            "\r\n",
            "Anderical FLICK door flips on a BUSINESS on that desk; Andrew's\r\n",
            "widen uniquenef out of the car as it passes\r\n",
            "into the camera, with casual, as if trying to kiss him.\r\n",
            "\r\n",
            "                                                            CUT.\r\n",
            "\r\n",
            "They're filming from the rainstaits, triggers and needs\r\n",
            "are to rockours, climbing down the corridors down from the passenger\r\n",
            "board)\r\n",
            "  I -aw mentime as...\r\n",
            "\r\n",
            "    MIRIAM\r\n",
            "  He sees...\r\n",
            "\r\n",
            " Catherine.  The screen SNAPS metallic on July 23 in quick mirror,\r\n",
            " doesn't do not feel in the door...\r\n",
            "\r\n",
            "Nothing as he's all just staring down.  We find reveals the class room for\r\n",
            "silence, not how much tire-relentless boxes. Though Kate Ask \r\n",
            "abandoned; it won't meet for.    She looks up and goes to Say and a dust of debris sits on\r\n",
            "the panel, opens the bolt of an exchange asphalt.\r\n",
            "\r\n",
            "The camera is albeviated.  The camera sits down, like the\r\n",
            "misty food, in a maze of course panel. Something scroughes to\r\n",
            "one side of the byd and swings out the camera. Stop im\r\n",
            "monitoring.\r\n",
            "\r\n",
            "                    VIKTOR\r\n",
            "           I have to drop the street as that\r\n",
            "          guys draw the bar and wait for a\r\n",
            "           squad of Albert, did god don't\r\n",
            "          come care of how long that, it looks\r\n",
            "          everything.\r\n",
            "\r\n",
            "                     MATT\r\n",
            "          Fine. You know, What's wrong.\r\n",
            "\r\n",
            "                    NATHAN (CONT'D)\r\n",
            "          This is for Straddge misters; shaped\r\n",
            "          most last time and all this\r\n",
            "          been my blackness will ever excuse\r\n",
            "          their guns from sort.\r\n",
            "\r\n",
            "                                   DININg ROOM\r\n",
            "\r\n",
            "                                   You want to find out that was that\r\n",
            "                    it does. You just need to sick in the\r\n",
            "                    fucking cells.\r\n",
            "\r\n",
            "Motely clatter doesn't move from her...\r\n",
            "\r\n",
            "5 INT. HALL - DAY\r\n",
            "\r\n",
            "The car waves in a frezzlen field, hangs at the seat creaks; Matt\r\n",
            "plays the bandit like as a goblet unlocking it, for you left\r\n",
            "too.\r\n",
            "\r\n",
            "               MUTTERIE\r\n",
            "                      I still sits nervously across\r\n",
            "                                        my feet about...\r\n",
            "\r\n",
            "               ANDREW (O.S.)\r\n",
            "          Who told you what?\r\n",
            "\r\n",
            "                                   DOOLITTLE\r\n",
            "                              (beat)\r\n",
            "                    Well... I am not having the intervice.\r\n",
            "                     Now I won't let im-taila concern!\r\n",
            "              (beat)\r\n",
            "          Norma, and I don't even know, that me\r\n",
            "          are a join in clear.\r\n",
            "\r\n",
            "                                   CLOSEY MATT\r\n",
            "           Repeat, Mars. He was calling you\r\n",
            "          just suppose Torth touches the same in\r\n",
            "          last. You're the apparatus.\r\n",
            "                                                           27.\r\n",
            "\r\n",
            "\r\n",
            "                                   ANDREW\r\n",
            "                        (CONFUSED)\r\n",
            "\r\n",
            "                                   STEVE (O.S.)\r\n",
            "           Are you frigned just mean that\r\n",
            "           attacked too.  Embeds we canno\r\n",
            "          don't seem to speak. Lits to\r\n",
            "          it all sog.\r\n",
            "\r\n",
            "Machine SUDDENLY S \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 21.14019465446472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peugiDBEKru",
        "outputId": "4f1dd69f-b73e-469c-fe21-e7eab88b1e69"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-6HYs3AEMSk",
        "outputId": "0b3b430d-8b2b-4e70-841e-9f663afcfaa6"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\r\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\r\n",
        "!apt-get update -qq 2>&1 > /dev/null\r\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "creds = GoogleCredentials.get_application_default()\r\n",
        "import getpass\r\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\r\n",
        "vcode = getpass.getpass()\r\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.24-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.24-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsgV3cmNEqma",
        "outputId": "c987d254-c20f-417b-c422-5150ab46eda2"
      },
      "source": [
        "!nvidia-smi\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 17 20:21:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}